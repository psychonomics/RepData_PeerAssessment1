with(subset(df.inf, mediapo_site == "Did Not Visit"),
qqnorm(ftpo_pres, main = "Normal Q-Q Plot: Did Not Visit))
par(mfrow=c(1,1))
par(mfrow=c(1,2))
with(subset(df.inf, mediapo_site == "Visited Web Site(S)"),
qqnorm(ftpo_pres, main = "Normal Q-Q Plot: Visited Web Site"))
with(subset(df.inf, mediapo_site == "Did Not Visit"),
qqnorm(ftpo_pres, main = "Normal Q-Q Plot: Did Not Visit"))
par(mfrow=c(1,1))
par(mfrow=c(1,2))
with(subset(df.inf, mediapo_site == "Did Not Visit"),
hist(ftpo_pres, main = "Did Not Visit",
ylab = "Feeling Thermometer"))
with(subset(df.inf, mediapo_site == "Visited Web Site(S)"),
hist(ftpo_pres, main = "Did Visit Website(s)",
ylab = "Feeling Thermometer"))
par(mfrow=c(1,1))
par(mfrow=c(1,2))
with(subset(df.inf, mediapo_site == "Visited Web Site(S)"),
qqnorm(ftpo_pres, main = "Normal Q-Q Plot: Visited Web Site"))
with(subset(df.inf, mediapo_site == "Did Not Visit"),
qqnorm(ftpo_pres, main = "Normal Q-Q Plot: Did Not Visit"))
par(mfrow=c(1,1))
```
inference(y = df.inf$ftpo_pres,
x = df.inf$mediapo_site,
type = "ht",
method = "simulation",
conflevel = 0.95,
alternative = "twosided",
null = 0,
est = "median",
boot_method = "perc")
by(anes$ftpo_pres[!is.na(anes$ftpo_pres)],
anes$mediapo_site[!is.na(anes$ftpo_pres)], median)
by(anes$ftpo_pres[!is.na(anes$ftpo_pres)],
anes$mediapo_site[!is.na(anes$ftpo_pres)], summary)
by(anes$ftpo_pres[!is.na(anes$ftpo_pres)],
anes$mediapo_site[!is.na(anes$ftpo_pres)], var)
par(mfrow=c(1,2))
with(subset(df.inf, mediapo_site == "Visited Web Site(S)"),
qqnorm(ftpo_pres, main = "Normal Q-Q Plot: Visited"))
with(subset(df.inf, mediapo_site == "Did Not Visit"),
qqnorm(ftpo_pres, main = "Normal Q-Q Plot: Did Not"))
par(mfrow=c(1,1))
```
class(df.inf$mediapo_site)
inference(y = df.inf$ftpo_pres,
x = df.inf$mediapo_site,
type = "ht",
method = "simulation",
conflevel = 0.95,
alternative = "twosided",
null = 0,
est = "mean",
boot_method = "perc",
eda_plot = FALSE,
inf_plot = FALSE,
sum_stats = TRUE)
summary(anes$mediapo_site)
plot(anes$mediapo_site,
main = "Candidate Website Visit(s)")
inference(y = df.inf$ftpo_pres,
x = df.inf$mediapo_site,
est = "median",
type = "ci",
method = "simulation",
alternative = "twosided",
conflevel = 0.95,
boot_method = "perc",
nsim = 10000,
seed = 1,
sum_stats = TRUE,
eda_plot = FALSE,
inf_plot = FALSE)
inference(y = df.inf$ftpo_pres,
x = df.inf$mediapo_site,
est = "mean",
type = "ht",
method = "simulation",
null = 0,
alternative = "twosided",
siglevel = 0.95,
boot_method = "perc",
nsim = 10000,
seed = 1,
sum_stats = TRUE,
eda_plot = FALSE,
inf_plot = FALSE)
names(airquality) <- tolower(names(airquality))
head(airquality)
names(airquality) <- tolower(names(airquality))
head(airquality)
aql <- melt(airquality) # [a]ir [q]uality [l]ong format
install.packages("reshape2")
require(reshape2)
aql <- melt(airquality) # [a]ir [q]uality [l]ong format
head(aql)
tail(aql)
aql.id.vars <- melt(airquality, id.vars = c("month", "day"))
head(aql.id.vars)
aql.id.vars.col.names <- melt(airquality, id.vars = c("month", "day"),
variable.name = "climate_variable",
value.name = "climate_value")
head(aql.id.vars.col.names)
# Reshape2 Package - Tidy Data is Long, not Wide
#### http://www.seananderson.ca/2013/10/19/reshape.html
Long-format data has a column for possible variable types and a column for the values of those variables. Long-format data isn’t necessarily only two columns. For example, we might have ozone measurements for each day of the year. In that case, we could have another column for day. In other words, there are different levels of “longness”. The ultimate shape you want to get your data into will depend on what you are doing with it.
It turns out that you need wide-format data for some types of data analysis and long-format data for others. In reality, you need long-format data much more commonly than wide-format data. For example, ggplot2 requires long-format data (technically tidy data), plyr requires long-format data, and most modelling functions (such as lm(), glm(), and gam()) require long-format data. But people often find it easier to record their data in wide format.
### The reshape2 package
```{r}
require(reshape2)
```
reshape2 is based around two key functions: melt and cast:
* melt takes wide-format data and melts it into long-format data.
* cast takes long-format data and casts it into wide-format data.
Think of working with metal: if you melt metal, it drips and becomes long. If you cast it into a mould, it becomes wide.
### Wide- to long-format data: the melt function
For this example we’ll work with the airquality dataset that is built into R. First we’ll change the column names to lower case to make them easier to work with. Then we’ll look at the data:
```{r}
names(airquality) <- tolower(names(airquality))
head(airquality)
```
What happens if we run the function melt with all the default argument values?
```{r}
aql <- melt(airquality) # [a]ir [q]uality [l]ong format
head(aql)
```
```{r}
tail(aql)
```
By default, melt has assumed that all columns with numeric values are variables with values. Often this is what you want.
Maybe here we want to know the values of ozone, solar.r, wind, and temp for each month and day. We can do that with melt by telling it that we want month and day to be “ID variables”.
ID variables are the variables that identify individual rows of data.
```{r}
aql.id.vars <- melt(airquality, id.vars = c("month", "day"))
head(aql.id.vars)
```
What if we wanted to control the column names in our long-format data?
melt lets us set those too all in one step:
```{r}
aql.id.vars.col.names <- melt(airquality, id.vars = c("month", "day"),
variable.name = "climate_variable",
value.name = "climate_value")
head(aql.id.vars.col.names)
```
### Long- to wide-format data: the cast functions
Whereas going from wide- to long-format data is pretty straightforward, going from long- to wide-format data can take a bit more thought. It usually involves some head scratching and some trial and error for all but the simplest cases. Let’s go through some examples.
In reshape2 there are multiple cast functions. Since you will most commonly work with data.frame objects, we’ll explore the dcast function. (There is also acast to return a vector, matrix, or array.)
Let’s take the long-format airquality data and cast it into some different wide formats. To start with, we’ll recover the same format we started with and compare the two.
##### dcast uses a formula to describe the shape of the data.
* The arguments on the left refer to the ID variables and the arguments on the right refer to the measured variables.
* Coming up with the right formula can take some trial and error at first.
* So, if you’re stuck don’t feel bad about just experimenting with formulas.
* There are usually only so many ways you can write the formula.
* Here, we need to tell dcast that month and day are the ID variables (we want a column for each) and that variable describes the measured variables. * Since there is only one remaining column, dcast will figure out that it contains the values themselves.
* We could explicitly declare this with value.var. (And in some cases it will be necessary to do so.)
```{r}
aql.id.vars <- melt(airquality, id.vars = c("month", "day"))
aqw.id.vars <- dcast(aql.id.vars, month + day ~ variable)
head(aqw.id.vars)
```
head(aqw.id.vars)
aql.id.vars <- melt(airquality, id.vars = c("month", "day"))
aqw.id.vars <- dcast(aql.id.vars, month + day ~ variable)
head(aql.id.vars.col.names)
head(aqw.id.vars)
aql.mth.day <- melt(airquality, id.vars = c("month", "day"))
aqw.mth.day <- dcast(aql.mth.day, month + day ~ variable)
head(aqw.id.vars)
head(aql.mth.day)
summary(aql.mth.day$variable)
head(aqw.id.vars)
head(airquality) # original data
summary(aql.mth.day$variable)
names(aql.mth.day)
aqw.mth.day <- dcast(aql.mth.day, month + day ~ variable, value.var = value)
aqw.mth.day <- dcast(aql.mth.day, month + day ~ variable, value.var = value)
aqw.mth.day <- dcast(aql.mth.day, month + day ~ variable)
head(aqw.id.vars)
head(airquality) # original data
dcast(aql, month ~ variable)
dcast(aql.mth.day, month ~ variable)
dcast(aql.mth.day, month ~ variable, fun.aggregate = mean,
na.rm = TRUE)
?dcast
help(package = "reshape2")
install.packages(c("evaluate", "lattice", "markdown"))
origdata.wide <- read.table(header=T, text='
subject sex control cond1 cond2
1   M     7.9  12.3  10.7
2   F     6.3  10.6  11.1
3   F     9.5  13.1  13.8
4   M    11.5  13.4  12.9
')
require(reshape2)
origdata.wide$subject <- factor(origdata.wide$subject)
origdata.long <- read.table(header=T, text='
subject sex condition measurement
1   M   control         7.9
1   M     cond1        12.3
1   M     cond2        10.7
2   F   control         6.3
2   F     cond1        10.6
2   F     cond2        11.1
3   F   control         9.5
3   F     cond1        13.1
3   F     cond2        13.8
4   M   control        11.5
4   M     cond1        13.4
4   M     cond2        12.9
')
origdata.wide
melt(origdata.wide, id.vars=c("subject","sex"))
data.long <- melt(origdata.wide,
# ID variables - all the variables to keep but not split apart on
id.vars=c("subject","sex"),
# The source columns
measure.vars=c("control", "cond1", "cond2" ),
# Name of the destination column that will identify the original
# column that the measurement came from
variable.name="condition",
value.name="measurement"
)
head(data.long)
origdata.wide
head(data.long, 12)
origdata.wide
head(data.long, 12)
levels(data.long$condition)[levels(data.long$condition)=="cond1"] <- "first"
levels(data.long$condition)[levels(data.long$condition)=="cond2"] <- "second"
data.long <- data.long[ order(data.long$subject, data.long$condition), ]
head(data.long, 12)
Optional Post-Melt Changes: Rename the factor levels of the variable column
head(data.long, 12)
origdata.long
data.wide <- dcast(origdata.long,
subject + sex ~ condition,
value.var="measurement")
head(data.wide)
names(data.wide)[names(data.wide)=="cond1"] <- "first"
names(data.wide)[names(data.wide)=="cond2"] <- "second"
data.wide <- data.wide[, c(1,2,5,3,4)]
head(data.wide)
install.packages("KernSmooth")
library(KernSmooth)
install.packages(c("shiny", "pamr", "filehash", "rpart"))
library(filehash)
library(rpart)
library(pamr)
library(shiny)
?shiny
?shiny```
?pamr
??pamr
?filehash
??filehash
?rpart
f <- function(x) {
g <- function(y) {
y + z
}
z <- 4
x + g(x)
}
f <- function(x) {
g <- function(y) {
y + z
}
z <- 4
x + g(x)
}
z <- 10
f(3)
x <- 5
y <- if(x < 3) {
NA
} else {
10
}
x <- 5
y <- if(x < 3) {
NA
} else {
10
}
y <- NA
x <- 5
y <- if(x < 3) {
NA
} else {
10
}
library(datasets)
data(iris)
library(datasets)
data(iris)
?iris
mean(iris$Sepal.Length)
colMeans(iris)
apply(iris[, 1:4], 1, mean)
apply(iris, 2, mean)  # Column means for all variables
apply(iris[, 1:4], 2, mean)
apply(iris, 2, mean)  # Column means for all variables
names(iris)
library(datasets)
data(mtcars)
?mtcars
lapply(mtcars, mean)  # Return a list
tapply(mtcars$mpg, mtcars$cyl, mean) # Return a tidy
?tapply
tmp <- tapply(mtcars$mpg, mtcars$cyl, mean) # Return a tidy
class(tmp)
tapply(mtcars$cyl, mtcars$mpg, mean)
split(mtcars, mtcars$cyl)
?split
tapply(mtcars$mpg, mtcars$cyl, mean) # Return a tidy array (mpg for each cyl)
mpg.cyl <- tapply(mtcars$mpg, mtcars$cyl, mean) # array (mpg for each cyl)
mpg.cyl[1] - mpg.cyl[2]
abs(mpg.cyl[1] - mpg.cyl[2])
mpg.cyl[1] - mpg.cyl[2]
debug(ls)
ls
hp.cyl <- tapply(mtcars$hp, mtcars$cyl, mean) # array (mpg for each cyl)
exit
quit
return
resume
up
end
finish
resume
hp.cyl <- tapply(mtcars$hp, mtcars$cyl, mean) # array (mpg for each cyl)
Q()
undebug
undebug(ls)
quit
quit
quit()
debugonce()
debugonce(ls)
undebug(ls)
undebug()
c
c
hp.cyl <- tapply(mtcars$hp, mtcars$cyl, mean) # array (mpg for each cyl)
abs(hp.cyl[1] - hp.cyl[2])
tapply(mtcars$hp, mtcars$cyl, mean) # array (mpg for each cyl)
hp.cyl <- tapply(mtcars$hp, mtcars$cyl, mean) # array (mpg for each cyl)
abs(hp.cyl[1] - hp.cyl[2])
with(mtcars, tapply(mpg, cal, mean))
lapply(mtcars, mean)
mean(mtcars$mpg, mtcars$cyl)
apply(mtcars, 2, mean)
mean(mtcars$mpg, mtcars$cyl)
lapply(mtcars, mean)
with(mtcars, tapply(mpg, cal, mean))
with(mtcars, tapply(mpg, cyl, mean))
with(subset(iris, Species == "Virginica"), mean(iris$Sepal.Length))
mean(iris$Sepal.Length)
with(subset(iris, Species == "virginica"), mean(iris$Sepal.Length))
names(iris)
names(iris$Species)
levels(iris$Species)
tapply(iris$Sepal.Length, iris$Species, mean)
install.packages("Rtools")
setwd("C:/Users/Tim/Dropbox/0.Coding/DS5-Reproducible-Research-John-Hopkins/RepData_PeerAssessment1")
---
output: html_document
---
# Reproducible Research: Peer Assessment 1
## Loading and preprocessing the data
```{r, echo=FALSE}
df0.raw <- read.csv("./activity/activity.csv")
```
#### steps: Number of steps taking in a 5-minute interval
#### date: The date on which the measurement was taken in YYYY-MM-DD format
#### interval: Identifier for the 5-minute interval in which measurement was taken
#### Take a look at the raw data
```{r, echo=FALSE}
str(df0.raw)
head(df0.raw)
tail(df0.raw)
summary(df0.raw)
```
#----------------------------------------------------------------------
## What is mean total number of steps taken per day?
#### For this part of the assignment, you can ignore the missing values in the dataset.
#### Make a histogram of the total number of steps taken each day
```{r, echo=FALSE}
hist(df0.raw$steps,
xlab = "Total number of steps taken each day",
main = "Total number of steps taken each day")
#?hist
```
#### Calculate and report the mean and median total number of steps taken per day
```{r, echo=FALSE}
mean.steps <- mean(df0.raw$steps, na.rm = TRUE)
median.steps <- median(df0.raw$steps, na.rm = TRUE)
print(mean.steps)
print(median.steps)
```
## What is the average daily activity pattern?
#### Make a time series plot (i.e. type = "l") of the 5-minute interval (x-axis) and the average number of steps taken, averaged across all days (y-axis)
```{r, echo=FALSE}
# Create a new dataset, containing complete cases only
df1.na.omit <- na.omit(df0.raw)
# Aggregate the number of steps (average accross all the days) by 5-minute interval
df2.steps.interval <- aggregate(x = df1.na.omit[ , "steps"], by = list(x = df1.na.omit$interval),
FUN = mean, na.rm = TRUE)
# Update the names of the new dataframe
names(df2.steps.interval) <- c("interval", "mean.steps")
```
```{r, echo=FALSE}
# Plot the 5-minute interval (x-axis)
with(df2.steps.interval, plot(x = interval, y = mean.steps,
type = "l",
xlab = "5-minute interval",
ylab = "Number of steps",
main = "Average daily activity pattern"))
```
#### Which 5-minute interval, on average across all the days in the dataset, contains the maximum number of steps?
```{r, echo=FALSE}
# Identify the 5-minute interval containing the maximum number of steps
df2.steps.interval[which.max(df2.steps.interval[ , 2]), ]
```
## Imputing missing values
#### Note that there are a number of days/intervals where there are missing values (coded as NA). The presence of missing days may introduce bias into some calculations or summaries of the data.
#### Calculate and report the total number of missing values in the dataset (i.e. the total number of rows with NAs)
```{r, echo=FALSE}
# Calculate the total number of rows with NA
nrow(df0.raw[!complete.cases(df0.raw), ])
```
#### Devise a strategy for filling in all of the missing values in the dataset. The strategy does not need to be sophisticated. For example, you could use the mean/median for that day, or the mean for that 5-minute interval, etc.
#### Create a new dataset that is equal to the original dataset but with the missing data filled in.
```{r, echo=FALSE}
# Create a new dataset, raw merged with the average number of steps for each 5-minute interval
df3.replace <- merge(df0.raw, df2.steps.interval, by = intersect(names(df0.raw), names(df2.steps.interval)))
# Create a new variable that is a copy of steps
df3.replace <- within(df3.replace, steps.replace <- df3.replace$steps)
df3.replace$steps.replace <- ifelse(is.na(df3.replace$steps), df3.replace$mean.steps,
df3.replace$steps.replace)
```
#### Make a histogram of the total number of steps taken each day and Calculate and report the mean and median total number of steps taken per day. Do these values differ from the estimates from the first part of the assignment? What is the impact of imputing missing data on the estimates of the total daily number of steps?
```{r, echo=FALSE}
hist(df3.replace$steps.replace,
xlab = "Total number of steps taken each day",
main = "Total number of steps taken each day")
#?hist
```
# The histogram is very similar, with a higher frequency, for each day
```{r, echo=FALSE}
mean.steps.replace <- mean(df3.replace$steps.replace, na.rm = TRUE)
median.steps.replace <- median(df3.replace$steps.replace, na.rm = TRUE)
print(mean.steps.replace)
print(median.steps.replace)
```
# I get the same answer!
```{r, echo=FALSE}
mean.steps.replace == mean.steps
median.steps.replace == median.steps
```
## Are there differences in activity patterns between weekdays and weekends?
#### For this part the weekdays() function may be of some help here. Use the dataset with the filled-in missing values for this part.
#### Create a new factor variable in the dataset with two levels ? ?weekday? and ?weekend? indicating whether a given date is a weekday or weekend day.
```{r, echo=FALSE}
# Create a new date variable using POSIXt format
df3.replace$date.Ymd <- strptime(df3.replace$date, format = "%Y-%m-%d")
# Create a new chr variable containing the weekday
df3.replace$day <- weekdays(df3.replace$date.Ymd)
#?weekdays  # Extract Parts of a POSIXt or Date Object
# Create a new factor variable containing the type of day
df3.replace$day.type <- as.factor(ifelse(df3.replace$day %in% c("Saturday", "Sunday"), "weekend", "weekday"))
```
#### Make a panel plot containing a time series plot (i.e. type = "l") of the 5-minute interval (x-axis) and the average number of steps taken, averaged across all weekday days or weekend days (y-axis). The plot should look something like the following, which was creating using simulated data:
```{r, echo=FALSE}
par(mfrow = c(1, 2))
with(df2.steps.interval[df3.replace$day.type == "weekday", ], plot(x = interval, y = mean.steps,
type = "l",
xlab = "5-minute interval",
ylab = "Number of steps",
main = "Average daily activity pattern"))
with(df2.steps.interval[df3.replace$day.type == "weekend", ], plot(x = interval, y = mean.steps,
type = "l",
xlab = "5-minute interval",
ylab = "Number of steps",
main = "Average daily activity pattern"))
```
par(mfrow = c(2, 1))
with(df2.steps.interval[df3.replace$day.type == "weekday", ], plot(x = interval, y = mean.steps,
type = "l",
xlab = "5-minute interval",
ylab = "Number of steps",
main = "Average daily activity pattern"))
with(df2.steps.interval[df3.replace$day.type == "weekend", ], plot(x = interval, y = mean.steps,
type = "l",
xlab = "5-minute interval",
ylab = "Number of steps",
main = "Average daily activity pattern"))
par(mfrow = c(2, 1))
with(df2.steps.interval[df3.replace$day.type == "weekday", ], plot(x = interval, y = mean.steps,
type = "l",
xlab = "5-minute interval",
ylab = "Number of steps",
main = "Average daily activity pattern - weekday"))
with(df2.steps.interval[df3.replace$day.type == "weekend", ], plot(x = interval, y = mean.steps,
type = "l",
xlab = "5-minute interval",
ylab = "Number of steps",
main = "Average daily activity pattern - weekend"))
```
?plot
